{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a jupyter server on Newtown with \n",
    "# conda activate __\n",
    "# srun --gres=gpu:L40:1  -c2 jupyter_lab.sh \n",
    "# Remotely connect to the kernel from local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers datasets\n",
    "# !pip install git+https://github.com/neelnanda-io/TransformerLens\n",
    "# !pip install pytest\n",
    "# !pip install huggingface_hub\n",
    "# !pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Mar 22 10:06:05 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.154.05             Driver Version: 535.154.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA L40S                    On  | 00000000:B4:00.0 Off |                  Off |\n",
      "| N/A   34C    P0              63W / 350W |      0MiB / 49140MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Make sure you have at least 30GB. The model itself (llama-2-7b) is 25GB\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first time you run this, you have to login to huggingface.\n",
    "# Also, your huggingface account should have access to llama-2-7b https://huggingface.co/meta-llama/Llama-2-7b  (First request from Meta \n",
    "#   and then from huggingface)\n",
    "\n",
    "# from huggingface_hub import notebook_login\n",
    "# notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if not torch.cuda.is_available():\n",
    "    print(\"WARNING: Running on CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, LlamaTokenizer, AutoTokenizer\n",
    "from tqdm.notebook import tqdm\n",
    "from jaxtyping import Float\n",
    "\n",
    "import transformer_lens\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens.hook_points import (\n",
    "    HookPoint,\n",
    ")  # Hooking utilities\n",
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from einops import einsum\n",
    "from dataclasses import dataclass\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer Lens Library is too buggy with large models, scroll down until you find LLama7BHelper and work with that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79b8234d819f48c2a8941d5dd46125b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0390dcebaa9f47efa939a53e96e0b568",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0a32741558a4e97825568bfe63a351a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bebb51db66624519ae5b2842de0dc782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab2a22288d9d4062848e2ee00f156767",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cb3320a22d74025a88290dc2165081d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34e7d500275046849638f4a4c6e3e777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ac922652a3041fd9022eea3731e07b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'The capital of Germany is now home to a new breed of German-made cars, with the latest model being the BMW M'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Working with the Transformer Lens library\n",
    "\n",
    "# https://colab.research.google.com/github/neelnanda-io/TransformerLens/blob/main/demos/LLaMA.ipynb#scrollTo=WuzUQA3wzthK\n",
    "\n",
    "LLAMA_2_7B_PATH = 'meta-llama/Llama-2-7b-hf'\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(LLAMA_2_7B_PATH)\n",
    "# hf_model = AutoModelForCausalLM.from_pretrained(LLAMA_2_7B_PATH, low_cpu_mem_usage=True)\n",
    "\n",
    "# model = HookedTransformer.from_pretrained(LLAMA_2_7B_PATH, device=device, fold_ln=False, center_writing_weights=False, center_unembed=False)\n",
    "model = HookedTransformer.from_pretrained('gpt2-small', device=device, fold_ln=False, center_writing_weights=False, center_unembed=False)\n",
    "model.generate(\"The capital of Germany is\", max_new_tokens=20, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 25.73937702178955 GB\n"
     ]
    }
   ],
   "source": [
    "print(f' {torch.cuda.memory_allocated() / 2**30} GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cfg.use_attn_in = False\n",
    "model.cfg.use_split_qkv_input = False\n",
    "model.cfg.use_attn_result = False\n",
    "model.cfg.use_hook_mlp_in = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the AGNEWS dataset. Uncomment below and run once\n",
    "# Note, your terminal should be running one directory above the git repo top-level directory ICL-GD\n",
    "\n",
    "AG_NEWS_LABEL_TO_WORD = {\n",
    "    0: 'World',\n",
    "    1: 'Sports',\n",
    "    2: 'Business',\n",
    "    3: 'Technology',\n",
    "}\n",
    "\n",
    "AG_NEWS_INSTRUCTION = 'Classify the news articles into the categories of World, Sports, Business, and Technology.\\n'\n",
    "\n",
    "\n",
    "def prepare_icl_dataset(ds, n_demonstrations, n_prompts, seed=None):\n",
    "    # Same seed guarantees same random sampling from ag_news dataset.\n",
    "    # Order of sampling: 1.test prompt 2. demonstrations\n",
    "    icl_ds = []\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "    test_indices = rng.choice(len(ds), size=(n_prompts,), replace=False)\n",
    "    for i in range(n_prompts):\n",
    "        icl_prompt = AG_NEWS_INSTRUCTION\n",
    "        zsl_prompt = icl_prompt\n",
    "\n",
    "        test_index = int(test_indices[i])\n",
    "        test_data_point = ds[test_index]\n",
    "        indices_wo_test = list(range(len(ds)))\n",
    "        indices_wo_test.remove(test_index)\n",
    "        test_text, test_label = test_data_point['text'], AG_NEWS_LABEL_TO_WORD[test_data_point['label']]\n",
    "\n",
    "        dem_indices = rng.choice(indices_wo_test, size=(n_demonstrations, ), replace=False)\n",
    "        for j in range(n_demonstrations):\n",
    "            data_point = ds[int(dem_indices[j])]\n",
    "            text, label = data_point['text'], AG_NEWS_LABEL_TO_WORD[data_point['label']]\n",
    "            icl_prompt += f\"News: {text}\\nCategory: {label}\\n\"\n",
    "        zsl_prompt += f\"News: {test_text}\\nCategory:\"\n",
    "        icl_prompt += f\"News: {test_text}\\nCategory:\"\n",
    "        icl_ds.append({'ICL Prompt': icl_prompt, 'ZSL Prompt': zsl_prompt,'Answer': test_label})\n",
    "    icl_ds = pd.DataFrame(icl_ds)\n",
    "    return icl_ds\n",
    "\n",
    "# dataset = load_dataset('ag_news')\n",
    "# ds_train = dataset['train']\n",
    "# ds_test = dataset['test']\n",
    "# print(ds_train[0])\n",
    "# icl32_ds = prepare_icl_dataset(ds_train, 32, 100, seed=0)\n",
    "# icl32_ds.to_csv('ICL-GD/ICL-AGNews-Size100-32Dem.csv')\n",
    "# icl16_ds = prepare_icl_dataset(ds_train, 16, 100, seed=0)\n",
    "# icl16_ds.to_csv('ICL-GD/ICL-AGNews-Size100-16Dem.csv')\n",
    "# icl8_ds = prepare_icl_dataset(ds_train, 8, n_prompts=100, seed=0)\n",
    "# icl8_ds.to_csv('ICL-GD/ICL-AGNews-Size100-8Dem.csv')\n",
    "# icl4_ds = prepare_icl_dataset(ds_train, 4, n_prompts=100, seed=0)\n",
    "# icl4_ds.to_csv('ICL-GD/ICL-AGNews-Size100-4Dem.csv')\n",
    "\n",
    "# assert icl32_ds.loc[85, 'ZSL Prompt'] == icl16_ds.loc[0, 'ZSL Prompt']\n",
    "# print(f\"ICL Prompt:\\n {icl_ds.loc[0, 'ICL Prompt']}\")\n",
    "# print(f\"ZSL Prompt:\\n {icl_ds.loc[0, 'ZSL Prompt']}\")\n",
    "# print(\"Answer: \", icl_ds.loc[0, 'Answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "icl_ds = pd.read_csv('ICL-GD/ICL-AGNews-Size100-8Dem.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|endoftext|>Classify the news articles into the categories of World, Sports, Business, and Technology.\n",
      "News: AMD introduces low-cost Internet device Chip company Advanced Micro Devices Inc. on Thursday rolled out a low-cost Internet device aimed at underserved markets around the world.\n",
      "Category: News\n"
     ]
    }
   ],
   "source": [
    "# ZSL fails\n",
    "\n",
    "zsl_prompt_tokens = model.to_tokens(icl_ds.loc[1, 'ZSL Prompt']).detach().cpu()\n",
    "zsl_out = model.generate(zsl_prompt_tokens, max_new_tokens=1, temperature=0, verbose=False).squeeze()\n",
    "print(model.to_string(zsl_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|endoftext|>Classify the news articles into the categories of World, Sports, Business, and Technolo...\n",
      "...\n",
      "...University.\n",
      "Category: Technology\n",
      "News: Doctors wait for irritation to disappear Surgery on the Red Sox pitcher Curt Schilling #39;s right ankle apparently has been delayed at least a week because of an irritation in the area of the torn tendon sheath that is to be repaired.\n",
      "Category: Sports\n",
      "News: AMD introduces low-cost Internet device Chip company Advanced Micro Devices Inc. on Thursday announced\n"
     ]
    }
   ],
   "source": [
    "# ICL succeeds\n",
    "\n",
    "icl_prompt_tokens = model.to_tokens(icl_ds.loc[1, 'ICL Prompt']).detach().cpu()\n",
    "icl_out = model.generate(icl_prompt_tokens, max_new_tokens=1, temperature=0, verbose=False).squeeze()\n",
    "out_str = model.to_string(icl_out)\n",
    "print(f'{out_str[0:100]}...\\n...\\n...{out_str[-400:]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_accuracy_icl_zsl(model, ds, test_size, seed=None):\n",
    "    correct_icl = 0\n",
    "    correct_zsl = 0\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "    indices = rng.choice(len(ds), size=(test_size,), replace=False)\n",
    "    for i in tqdm(indices):\n",
    "        row = ds.iloc[i]\n",
    "        icl_prompt_tokens = model.to_tokens(row['ICL Prompt']).detach().cpu()\n",
    "        zsl_prompt_tokens = model.to_tokens(row['ZSL Prompt']).detach().cpu()\n",
    "        # out = model(prompt_tokens)\n",
    "        # print(type(out))\n",
    "        icl_out = model.generate(icl_prompt_tokens, max_new_tokens=1, temperature=0, verbose=False).squeeze()\n",
    "        zsl_out = model.generate(zsl_prompt_tokens, max_new_tokens=1, temperature=0, verbose=False).squeeze()\n",
    "        # print(f'Model: {model.to_string(out[0, -1])}, Answer: {row['Answer']}')\n",
    "        # print(out.size())\n",
    "        correct_icl += (model.to_string(icl_out[-1]) == row['Answer'])\n",
    "        correct_zsl += (model.to_string(zsl_out[-1]) == row['Answer'])\n",
    "\n",
    "    print(f'ICL accuracy: {correct_icl / test_size}')\n",
    "    print(f'ZSL accuracy: {correct_zsl / test_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 demonstrations:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a571430a845947a6a53d53a5d4fd34f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICL accuracy: 0.0\n",
      "ZSL accuracy: 0.0\n",
      "8 demonstrations:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c236328ef7142f4a582c750f4b1ebda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICL accuracy: 0.0\n",
      "ZSL accuracy: 0.0\n",
      "16 demonstrations:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cce74df631f43b3b08439230c23d0b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICL accuracy: 0.0\n",
      "ZSL accuracy: 0.0\n",
      "32 demonstrations:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0786beb6cc248fba109f86cea47e94b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICL accuracy: 0.0\n",
      "ZSL accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of  ICL, vs ZSL (note: different datasets, hence ZSL performance slightly different)\n",
    "# 8 demonstrations is already excellent\n",
    "\n",
    "for n_dems in (4, 8, 16, 32):\n",
    "    print(f'{n_dems} demonstrations:')\n",
    "    icl_ds = pd.read_csv(f'ICL-GD/ICL-AGNews-Size100-{n_dems}Dem.csv')\n",
    "    model_accuracy_icl_zsl(model, icl_ds, test_size=50, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32000, 4096])\n",
      "torch.Size([4096, 32000])\n",
      "['<s> Transformers']\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4, 32000])\n",
      "torch.Size([1, 4, 4096])\n",
      "['Institutionfigattedhips']\n",
      "['<s> Transformers']\n"
     ]
    }
   ],
   "source": [
    "# Transpose of embedding matrix actually works better than the unembedding matrix for the clean token embeddings\n",
    "# But probably not after layers\n",
    "\n",
    "W_embedding = model.W_E.to(device)\n",
    "W_unembedding = model.W_U.to(device)\n",
    "n_vocab = W_embedding.shape[0]\n",
    "print(W_embedding.shape)\n",
    "print(W_unembedding.shape)\n",
    "tokens = model.to_tokens('Transformers').to(device)\n",
    "print(model.to_string(tokens))\n",
    "print(tokens.shape)\n",
    "tokens_one_hot = torch.nn.functional.one_hot(tokens, num_classes=n_vocab).float()\n",
    "print(tokens_one_hot.shape)\n",
    "assert torch.all(torch.argmax(tokens_one_hot, dim=-1) == tokens)\n",
    "embeddings = torch.matmul(tokens_one_hot, W_embedding)\n",
    "print(embeddings.shape)\n",
    "back_to_tokens_one_hot = torch.matmul(embeddings, W_unembedding)\n",
    "back_to_tokens_one_hot_2 = torch.matmul(embeddings, W_embedding.T)\n",
    "back_to_tokens = torch.argmax(back_to_tokens_one_hot, dim=-1)\n",
    "back_to_tokens_2 = torch.argmax(back_to_tokens_one_hot_2, dim=-1)\n",
    "back_to_words = model.to_string(back_to_tokens)\n",
    "back_to_words_2 = model.to_string(back_to_tokens_2)\n",
    "print(back_to_words)\n",
    "print(back_to_words_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14693de980d14fe194909b6ab073ba95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> The capital of Germany is Berlin\n",
      "<s> The capital of Germany is Berlin.\n",
      "<s> The capital of Germany is Berlin. Berlin\n"
     ]
    }
   ],
   "source": [
    "token_tensor = model.generate('The capital of Germany is', max_new_tokens=3, temperature=0, return_type='tensor').squeeze()\n",
    "print(model.to_string(token_tensor[:-2]))\n",
    "print(model.to_string(token_tensor[:-1]))\n",
    "print(model.to_string(token_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.12.2 | packaged by Anaconda, Inc. | (main, Feb 27 2024, 17:35:02) [GCC 11.2.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb2b7da5f1b2427481d5d9f667d35336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/538 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f90a03bd66a84b5b882f82a329e9ffae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin.index.json:   0%|          | 0.00/42.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "578f6d7437424aab98703432ee7a0468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f33bf96f3b984b65b0b021aa3cf1f327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.91G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e7e8dbaf6e84376a8525c95db8a5504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00002-of-00002.bin:   0%|          | 0.00/3.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3388c06fb7c4d48a544997be8e6b28f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "990132e50022475798bc19eb94728aa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/394 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0071f6f44e55424dbb18534c4ffa7945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1024719670fe4e2fa7a5f68308deee26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model EleutherAI/pythia-6.9b-v0 into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "# LLAMA_2_7B_PATH = 'meta-llama/Llama-2-7b-hf'\n",
    "PYTHIA_PATH = 'EleutherAI/pythia-6.9b-v0'\n",
    "# hf_model = AutoModelForCausalLM.from_pretrained(LLAMA_2_7B_PATH, low_cpu_mem_usage=True)\n",
    "model = HookedTransformer.from_pretrained(model_name=PYTHIA_PATH, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([33, 6, 50432])\n",
      "tensor([ 3.7533, -3.5945,  5.3853,  4.7549,  1.2172], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([ 3.7533, -3.5945,  5.3853,  4.7549,  1.2172], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([-0.0123, -0.0102, -0.0152, -0.0151, -0.0108, -0.0152, -0.0274, -0.5511,\n",
      "        -0.0113], device='cuda:0', grad_fn=<IndexBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# model = HookedTransformer.from_pretrained('gpt2-small', device=device, fold_ln=False, center_writing_weights=False, center_unembed=False)\n",
    "# model = HookedTransformer.from_pretrained('gpt2-small', device=device, fold_ln=False, center_unembed=True)\n",
    "\n",
    "# model = HookedTransformer.from_pretrained(LLAMA_2_7B_PATH, device=device, fold_ln=True, center_unembed=False, center_writing_weights=False, fold_value_biases=False)\n",
    "prompt = 'The capital of Germany is'\n",
    "logits, activation_cache = model.run_with_cache(prompt, return_cache_object=True, remove_batch_dim=True)\n",
    "logits = logits.squeeze(dim=0)\n",
    "accum_resid, labels = activation_cache.accumulated_resid(return_labels=True, apply_ln=True)\n",
    "unembedded = accum_resid @ model.W_U + model.b_U\n",
    "print(unembedded.shape)  # Layer, pos, d_model\n",
    "unembedded_last_layer = unembedded[-1, :, :]\n",
    "assert logits.shape == unembedded_last_layer.shape\n",
    "\n",
    "print(logits[-1, :5])\n",
    "print(unembedded_last_layer[-1, :5])\n",
    "\n",
    "print(((logits - unembedded_last_layer) / logits)[~torch.isclose(logits, unembedded_last_layer, rtol=1e-2)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to see the output for each layer - https://neelnanda-io.github.io/TransformerLens/generated/code/transformer_lens.ActivationCache.html#transformer_lens.ActivationCache.ActivationCache.accumulated_resid\n",
    "\n",
    "# Something is weird with the unembedding, it seems like it's not just as simple as multiplying by the unembedding matrix, because\n",
    "# doing that on the last layer doesn't yield the model's outputs\n",
    "\n",
    "def layer_prob(prompt):\n",
    "    with torch.no_grad():\n",
    "        logits, activation_cache = model.run_with_cache(prompt, return_cache_object=True)\n",
    "        final_answer_token = int(torch.argmax(logits[0, -1]))\n",
    "        # print(activation_cache.cache_dict.keys())\n",
    "        # print(logits.shape)\n",
    "        # print(logits[0, -1, :5])\n",
    "        # print(activation_cache.cache_dict['ln_final.hook_normalized'].shape)\n",
    "        # manual_logits = activation_cache.cache_dict['ln_final.hook_normalized'] / activation_cache['ln_final.hook_scale'] @ W_unembedding\n",
    "\n",
    "        # print()\n",
    "        # print(torch.argmax(logits[0, -1, :]))\n",
    "        # print(torch.argmax(manual_logits[0, -1, :]))\n",
    "\n",
    "        # print(manual_logits.shape)\n",
    "        # print(manual_logits[0, -1, :5])\n",
    "\n",
    "        # print((logits / manual_logits)[0, -1, :5])\n",
    "\n",
    "\n",
    "        # assert torch.equal(logits, manual_logits)\n",
    "\n",
    "        print(model.to_string(torch.argmax(logits[0, -1])))\n",
    "        accum_resid, labels = activation_cache.accumulated_resid(return_labels=True, apply_ln=False)\n",
    "        return accum_resid, labels, logits, activation_cache\n",
    "        last_token_accum = accum_resid[:, 0, -1, :]  # layer, batch, pos, d_model\n",
    "        # print(last_token_accum.shape)  # layer, d_model\n",
    "        last_token_unembedded = last_token_accum @ W_unembedding  # layer, d_vocab\n",
    "        # print(last_token_unembedded[-1, :5])\n",
    "        # assert last_token_unembedded[-1, :].shape == logits[0, -1].shape\n",
    "\n",
    "        plt.scatter(last_token_unembedded[-1].cpu(), logits[0, -1].cpu())\n",
    "\n",
    "        # print((last_token_unembedded[-1, :5] / manual_logits[0, -1, :5]))\n",
    "\n",
    "        # assert torch.equal(last_token_unembedded[-1, :], logits[0, -1])\n",
    "        probs = torch.softmax(last_token_unembedded, dim=-1)      # layer, d_vocab (probs)\n",
    "        # last_token_vocab_index = torch.argmax(last_token_unembedded, dim=-1, keepdim=True)\n",
    "        # print(model.to_string(final_answer_token))\n",
    "        # print(model.to_string(last_token_vocab_index))\n",
    "        # print(probs[:, final_answer_token])\n",
    "        return probs[:, final_answer_token]\n",
    "        plt.plot(list(range(probs.shape[0])), list(probs[:, final_answer_token].cpu()))\n",
    "        plt.semilogy()\n",
    "        plt.title('Confidence in Final Answer By Layer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berlin\n"
     ]
    }
   ],
   "source": [
    "accum_resid, labels, logits, activation_cache = layer_prob(\"The capital of Germany is\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['hook_embed', 'blocks.0.hook_resid_pre', 'blocks.0.ln1.hook_scale', 'blocks.0.ln1.hook_normalized', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k', 'blocks.0.attn.hook_v', 'blocks.0.attn.hook_rot_q', 'blocks.0.attn.hook_rot_k', 'blocks.0.attn.hook_attn_scores', 'blocks.0.attn.hook_pattern', 'blocks.0.attn.hook_z', 'blocks.0.hook_attn_out', 'blocks.0.hook_resid_mid', 'blocks.0.ln2.hook_scale', 'blocks.0.ln2.hook_normalized', 'blocks.0.mlp.hook_pre', 'blocks.0.mlp.hook_pre_linear', 'blocks.0.mlp.hook_post', 'blocks.0.hook_mlp_out', 'blocks.0.hook_resid_post', 'blocks.1.hook_resid_pre', 'blocks.1.ln1.hook_scale', 'blocks.1.ln1.hook_normalized', 'blocks.1.attn.hook_q', 'blocks.1.attn.hook_k', 'blocks.1.attn.hook_v', 'blocks.1.attn.hook_rot_q', 'blocks.1.attn.hook_rot_k', 'blocks.1.attn.hook_attn_scores', 'blocks.1.attn.hook_pattern', 'blocks.1.attn.hook_z', 'blocks.1.hook_attn_out', 'blocks.1.hook_resid_mid', 'blocks.1.ln2.hook_scale', 'blocks.1.ln2.hook_normalized', 'blocks.1.mlp.hook_pre', 'blocks.1.mlp.hook_pre_linear', 'blocks.1.mlp.hook_post', 'blocks.1.hook_mlp_out', 'blocks.1.hook_resid_post', 'blocks.2.hook_resid_pre', 'blocks.2.ln1.hook_scale', 'blocks.2.ln1.hook_normalized', 'blocks.2.attn.hook_q', 'blocks.2.attn.hook_k', 'blocks.2.attn.hook_v', 'blocks.2.attn.hook_rot_q', 'blocks.2.attn.hook_rot_k', 'blocks.2.attn.hook_attn_scores', 'blocks.2.attn.hook_pattern', 'blocks.2.attn.hook_z', 'blocks.2.hook_attn_out', 'blocks.2.hook_resid_mid', 'blocks.2.ln2.hook_scale', 'blocks.2.ln2.hook_normalized', 'blocks.2.mlp.hook_pre', 'blocks.2.mlp.hook_pre_linear', 'blocks.2.mlp.hook_post', 'blocks.2.hook_mlp_out', 'blocks.2.hook_resid_post', 'blocks.3.hook_resid_pre', 'blocks.3.ln1.hook_scale', 'blocks.3.ln1.hook_normalized', 'blocks.3.attn.hook_q', 'blocks.3.attn.hook_k', 'blocks.3.attn.hook_v', 'blocks.3.attn.hook_rot_q', 'blocks.3.attn.hook_rot_k', 'blocks.3.attn.hook_attn_scores', 'blocks.3.attn.hook_pattern', 'blocks.3.attn.hook_z', 'blocks.3.hook_attn_out', 'blocks.3.hook_resid_mid', 'blocks.3.ln2.hook_scale', 'blocks.3.ln2.hook_normalized', 'blocks.3.mlp.hook_pre', 'blocks.3.mlp.hook_pre_linear', 'blocks.3.mlp.hook_post', 'blocks.3.hook_mlp_out', 'blocks.3.hook_resid_post', 'blocks.4.hook_resid_pre', 'blocks.4.ln1.hook_scale', 'blocks.4.ln1.hook_normalized', 'blocks.4.attn.hook_q', 'blocks.4.attn.hook_k', 'blocks.4.attn.hook_v', 'blocks.4.attn.hook_rot_q', 'blocks.4.attn.hook_rot_k', 'blocks.4.attn.hook_attn_scores', 'blocks.4.attn.hook_pattern', 'blocks.4.attn.hook_z', 'blocks.4.hook_attn_out', 'blocks.4.hook_resid_mid', 'blocks.4.ln2.hook_scale', 'blocks.4.ln2.hook_normalized', 'blocks.4.mlp.hook_pre', 'blocks.4.mlp.hook_pre_linear', 'blocks.4.mlp.hook_post', 'blocks.4.hook_mlp_out', 'blocks.4.hook_resid_post', 'blocks.5.hook_resid_pre', 'blocks.5.ln1.hook_scale', 'blocks.5.ln1.hook_normalized', 'blocks.5.attn.hook_q', 'blocks.5.attn.hook_k', 'blocks.5.attn.hook_v', 'blocks.5.attn.hook_rot_q', 'blocks.5.attn.hook_rot_k', 'blocks.5.attn.hook_attn_scores', 'blocks.5.attn.hook_pattern', 'blocks.5.attn.hook_z', 'blocks.5.hook_attn_out', 'blocks.5.hook_resid_mid', 'blocks.5.ln2.hook_scale', 'blocks.5.ln2.hook_normalized', 'blocks.5.mlp.hook_pre', 'blocks.5.mlp.hook_pre_linear', 'blocks.5.mlp.hook_post', 'blocks.5.hook_mlp_out', 'blocks.5.hook_resid_post', 'blocks.6.hook_resid_pre', 'blocks.6.ln1.hook_scale', 'blocks.6.ln1.hook_normalized', 'blocks.6.attn.hook_q', 'blocks.6.attn.hook_k', 'blocks.6.attn.hook_v', 'blocks.6.attn.hook_rot_q', 'blocks.6.attn.hook_rot_k', 'blocks.6.attn.hook_attn_scores', 'blocks.6.attn.hook_pattern', 'blocks.6.attn.hook_z', 'blocks.6.hook_attn_out', 'blocks.6.hook_resid_mid', 'blocks.6.ln2.hook_scale', 'blocks.6.ln2.hook_normalized', 'blocks.6.mlp.hook_pre', 'blocks.6.mlp.hook_pre_linear', 'blocks.6.mlp.hook_post', 'blocks.6.hook_mlp_out', 'blocks.6.hook_resid_post', 'blocks.7.hook_resid_pre', 'blocks.7.ln1.hook_scale', 'blocks.7.ln1.hook_normalized', 'blocks.7.attn.hook_q', 'blocks.7.attn.hook_k', 'blocks.7.attn.hook_v', 'blocks.7.attn.hook_rot_q', 'blocks.7.attn.hook_rot_k', 'blocks.7.attn.hook_attn_scores', 'blocks.7.attn.hook_pattern', 'blocks.7.attn.hook_z', 'blocks.7.hook_attn_out', 'blocks.7.hook_resid_mid', 'blocks.7.ln2.hook_scale', 'blocks.7.ln2.hook_normalized', 'blocks.7.mlp.hook_pre', 'blocks.7.mlp.hook_pre_linear', 'blocks.7.mlp.hook_post', 'blocks.7.hook_mlp_out', 'blocks.7.hook_resid_post', 'blocks.8.hook_resid_pre', 'blocks.8.ln1.hook_scale', 'blocks.8.ln1.hook_normalized', 'blocks.8.attn.hook_q', 'blocks.8.attn.hook_k', 'blocks.8.attn.hook_v', 'blocks.8.attn.hook_rot_q', 'blocks.8.attn.hook_rot_k', 'blocks.8.attn.hook_attn_scores', 'blocks.8.attn.hook_pattern', 'blocks.8.attn.hook_z', 'blocks.8.hook_attn_out', 'blocks.8.hook_resid_mid', 'blocks.8.ln2.hook_scale', 'blocks.8.ln2.hook_normalized', 'blocks.8.mlp.hook_pre', 'blocks.8.mlp.hook_pre_linear', 'blocks.8.mlp.hook_post', 'blocks.8.hook_mlp_out', 'blocks.8.hook_resid_post', 'blocks.9.hook_resid_pre', 'blocks.9.ln1.hook_scale', 'blocks.9.ln1.hook_normalized', 'blocks.9.attn.hook_q', 'blocks.9.attn.hook_k', 'blocks.9.attn.hook_v', 'blocks.9.attn.hook_rot_q', 'blocks.9.attn.hook_rot_k', 'blocks.9.attn.hook_attn_scores', 'blocks.9.attn.hook_pattern', 'blocks.9.attn.hook_z', 'blocks.9.hook_attn_out', 'blocks.9.hook_resid_mid', 'blocks.9.ln2.hook_scale', 'blocks.9.ln2.hook_normalized', 'blocks.9.mlp.hook_pre', 'blocks.9.mlp.hook_pre_linear', 'blocks.9.mlp.hook_post', 'blocks.9.hook_mlp_out', 'blocks.9.hook_resid_post', 'blocks.10.hook_resid_pre', 'blocks.10.ln1.hook_scale', 'blocks.10.ln1.hook_normalized', 'blocks.10.attn.hook_q', 'blocks.10.attn.hook_k', 'blocks.10.attn.hook_v', 'blocks.10.attn.hook_rot_q', 'blocks.10.attn.hook_rot_k', 'blocks.10.attn.hook_attn_scores', 'blocks.10.attn.hook_pattern', 'blocks.10.attn.hook_z', 'blocks.10.hook_attn_out', 'blocks.10.hook_resid_mid', 'blocks.10.ln2.hook_scale', 'blocks.10.ln2.hook_normalized', 'blocks.10.mlp.hook_pre', 'blocks.10.mlp.hook_pre_linear', 'blocks.10.mlp.hook_post', 'blocks.10.hook_mlp_out', 'blocks.10.hook_resid_post', 'blocks.11.hook_resid_pre', 'blocks.11.ln1.hook_scale', 'blocks.11.ln1.hook_normalized', 'blocks.11.attn.hook_q', 'blocks.11.attn.hook_k', 'blocks.11.attn.hook_v', 'blocks.11.attn.hook_rot_q', 'blocks.11.attn.hook_rot_k', 'blocks.11.attn.hook_attn_scores', 'blocks.11.attn.hook_pattern', 'blocks.11.attn.hook_z', 'blocks.11.hook_attn_out', 'blocks.11.hook_resid_mid', 'blocks.11.ln2.hook_scale', 'blocks.11.ln2.hook_normalized', 'blocks.11.mlp.hook_pre', 'blocks.11.mlp.hook_pre_linear', 'blocks.11.mlp.hook_post', 'blocks.11.hook_mlp_out', 'blocks.11.hook_resid_post', 'blocks.12.hook_resid_pre', 'blocks.12.ln1.hook_scale', 'blocks.12.ln1.hook_normalized', 'blocks.12.attn.hook_q', 'blocks.12.attn.hook_k', 'blocks.12.attn.hook_v', 'blocks.12.attn.hook_rot_q', 'blocks.12.attn.hook_rot_k', 'blocks.12.attn.hook_attn_scores', 'blocks.12.attn.hook_pattern', 'blocks.12.attn.hook_z', 'blocks.12.hook_attn_out', 'blocks.12.hook_resid_mid', 'blocks.12.ln2.hook_scale', 'blocks.12.ln2.hook_normalized', 'blocks.12.mlp.hook_pre', 'blocks.12.mlp.hook_pre_linear', 'blocks.12.mlp.hook_post', 'blocks.12.hook_mlp_out', 'blocks.12.hook_resid_post', 'blocks.13.hook_resid_pre', 'blocks.13.ln1.hook_scale', 'blocks.13.ln1.hook_normalized', 'blocks.13.attn.hook_q', 'blocks.13.attn.hook_k', 'blocks.13.attn.hook_v', 'blocks.13.attn.hook_rot_q', 'blocks.13.attn.hook_rot_k', 'blocks.13.attn.hook_attn_scores', 'blocks.13.attn.hook_pattern', 'blocks.13.attn.hook_z', 'blocks.13.hook_attn_out', 'blocks.13.hook_resid_mid', 'blocks.13.ln2.hook_scale', 'blocks.13.ln2.hook_normalized', 'blocks.13.mlp.hook_pre', 'blocks.13.mlp.hook_pre_linear', 'blocks.13.mlp.hook_post', 'blocks.13.hook_mlp_out', 'blocks.13.hook_resid_post', 'blocks.14.hook_resid_pre', 'blocks.14.ln1.hook_scale', 'blocks.14.ln1.hook_normalized', 'blocks.14.attn.hook_q', 'blocks.14.attn.hook_k', 'blocks.14.attn.hook_v', 'blocks.14.attn.hook_rot_q', 'blocks.14.attn.hook_rot_k', 'blocks.14.attn.hook_attn_scores', 'blocks.14.attn.hook_pattern', 'blocks.14.attn.hook_z', 'blocks.14.hook_attn_out', 'blocks.14.hook_resid_mid', 'blocks.14.ln2.hook_scale', 'blocks.14.ln2.hook_normalized', 'blocks.14.mlp.hook_pre', 'blocks.14.mlp.hook_pre_linear', 'blocks.14.mlp.hook_post', 'blocks.14.hook_mlp_out', 'blocks.14.hook_resid_post', 'blocks.15.hook_resid_pre', 'blocks.15.ln1.hook_scale', 'blocks.15.ln1.hook_normalized', 'blocks.15.attn.hook_q', 'blocks.15.attn.hook_k', 'blocks.15.attn.hook_v', 'blocks.15.attn.hook_rot_q', 'blocks.15.attn.hook_rot_k', 'blocks.15.attn.hook_attn_scores', 'blocks.15.attn.hook_pattern', 'blocks.15.attn.hook_z', 'blocks.15.hook_attn_out', 'blocks.15.hook_resid_mid', 'blocks.15.ln2.hook_scale', 'blocks.15.ln2.hook_normalized', 'blocks.15.mlp.hook_pre', 'blocks.15.mlp.hook_pre_linear', 'blocks.15.mlp.hook_post', 'blocks.15.hook_mlp_out', 'blocks.15.hook_resid_post', 'blocks.16.hook_resid_pre', 'blocks.16.ln1.hook_scale', 'blocks.16.ln1.hook_normalized', 'blocks.16.attn.hook_q', 'blocks.16.attn.hook_k', 'blocks.16.attn.hook_v', 'blocks.16.attn.hook_rot_q', 'blocks.16.attn.hook_rot_k', 'blocks.16.attn.hook_attn_scores', 'blocks.16.attn.hook_pattern', 'blocks.16.attn.hook_z', 'blocks.16.hook_attn_out', 'blocks.16.hook_resid_mid', 'blocks.16.ln2.hook_scale', 'blocks.16.ln2.hook_normalized', 'blocks.16.mlp.hook_pre', 'blocks.16.mlp.hook_pre_linear', 'blocks.16.mlp.hook_post', 'blocks.16.hook_mlp_out', 'blocks.16.hook_resid_post', 'blocks.17.hook_resid_pre', 'blocks.17.ln1.hook_scale', 'blocks.17.ln1.hook_normalized', 'blocks.17.attn.hook_q', 'blocks.17.attn.hook_k', 'blocks.17.attn.hook_v', 'blocks.17.attn.hook_rot_q', 'blocks.17.attn.hook_rot_k', 'blocks.17.attn.hook_attn_scores', 'blocks.17.attn.hook_pattern', 'blocks.17.attn.hook_z', 'blocks.17.hook_attn_out', 'blocks.17.hook_resid_mid', 'blocks.17.ln2.hook_scale', 'blocks.17.ln2.hook_normalized', 'blocks.17.mlp.hook_pre', 'blocks.17.mlp.hook_pre_linear', 'blocks.17.mlp.hook_post', 'blocks.17.hook_mlp_out', 'blocks.17.hook_resid_post', 'blocks.18.hook_resid_pre', 'blocks.18.ln1.hook_scale', 'blocks.18.ln1.hook_normalized', 'blocks.18.attn.hook_q', 'blocks.18.attn.hook_k', 'blocks.18.attn.hook_v', 'blocks.18.attn.hook_rot_q', 'blocks.18.attn.hook_rot_k', 'blocks.18.attn.hook_attn_scores', 'blocks.18.attn.hook_pattern', 'blocks.18.attn.hook_z', 'blocks.18.hook_attn_out', 'blocks.18.hook_resid_mid', 'blocks.18.ln2.hook_scale', 'blocks.18.ln2.hook_normalized', 'blocks.18.mlp.hook_pre', 'blocks.18.mlp.hook_pre_linear', 'blocks.18.mlp.hook_post', 'blocks.18.hook_mlp_out', 'blocks.18.hook_resid_post', 'blocks.19.hook_resid_pre', 'blocks.19.ln1.hook_scale', 'blocks.19.ln1.hook_normalized', 'blocks.19.attn.hook_q', 'blocks.19.attn.hook_k', 'blocks.19.attn.hook_v', 'blocks.19.attn.hook_rot_q', 'blocks.19.attn.hook_rot_k', 'blocks.19.attn.hook_attn_scores', 'blocks.19.attn.hook_pattern', 'blocks.19.attn.hook_z', 'blocks.19.hook_attn_out', 'blocks.19.hook_resid_mid', 'blocks.19.ln2.hook_scale', 'blocks.19.ln2.hook_normalized', 'blocks.19.mlp.hook_pre', 'blocks.19.mlp.hook_pre_linear', 'blocks.19.mlp.hook_post', 'blocks.19.hook_mlp_out', 'blocks.19.hook_resid_post', 'blocks.20.hook_resid_pre', 'blocks.20.ln1.hook_scale', 'blocks.20.ln1.hook_normalized', 'blocks.20.attn.hook_q', 'blocks.20.attn.hook_k', 'blocks.20.attn.hook_v', 'blocks.20.attn.hook_rot_q', 'blocks.20.attn.hook_rot_k', 'blocks.20.attn.hook_attn_scores', 'blocks.20.attn.hook_pattern', 'blocks.20.attn.hook_z', 'blocks.20.hook_attn_out', 'blocks.20.hook_resid_mid', 'blocks.20.ln2.hook_scale', 'blocks.20.ln2.hook_normalized', 'blocks.20.mlp.hook_pre', 'blocks.20.mlp.hook_pre_linear', 'blocks.20.mlp.hook_post', 'blocks.20.hook_mlp_out', 'blocks.20.hook_resid_post', 'blocks.21.hook_resid_pre', 'blocks.21.ln1.hook_scale', 'blocks.21.ln1.hook_normalized', 'blocks.21.attn.hook_q', 'blocks.21.attn.hook_k', 'blocks.21.attn.hook_v', 'blocks.21.attn.hook_rot_q', 'blocks.21.attn.hook_rot_k', 'blocks.21.attn.hook_attn_scores', 'blocks.21.attn.hook_pattern', 'blocks.21.attn.hook_z', 'blocks.21.hook_attn_out', 'blocks.21.hook_resid_mid', 'blocks.21.ln2.hook_scale', 'blocks.21.ln2.hook_normalized', 'blocks.21.mlp.hook_pre', 'blocks.21.mlp.hook_pre_linear', 'blocks.21.mlp.hook_post', 'blocks.21.hook_mlp_out', 'blocks.21.hook_resid_post', 'blocks.22.hook_resid_pre', 'blocks.22.ln1.hook_scale', 'blocks.22.ln1.hook_normalized', 'blocks.22.attn.hook_q', 'blocks.22.attn.hook_k', 'blocks.22.attn.hook_v', 'blocks.22.attn.hook_rot_q', 'blocks.22.attn.hook_rot_k', 'blocks.22.attn.hook_attn_scores', 'blocks.22.attn.hook_pattern', 'blocks.22.attn.hook_z', 'blocks.22.hook_attn_out', 'blocks.22.hook_resid_mid', 'blocks.22.ln2.hook_scale', 'blocks.22.ln2.hook_normalized', 'blocks.22.mlp.hook_pre', 'blocks.22.mlp.hook_pre_linear', 'blocks.22.mlp.hook_post', 'blocks.22.hook_mlp_out', 'blocks.22.hook_resid_post', 'blocks.23.hook_resid_pre', 'blocks.23.ln1.hook_scale', 'blocks.23.ln1.hook_normalized', 'blocks.23.attn.hook_q', 'blocks.23.attn.hook_k', 'blocks.23.attn.hook_v', 'blocks.23.attn.hook_rot_q', 'blocks.23.attn.hook_rot_k', 'blocks.23.attn.hook_attn_scores', 'blocks.23.attn.hook_pattern', 'blocks.23.attn.hook_z', 'blocks.23.hook_attn_out', 'blocks.23.hook_resid_mid', 'blocks.23.ln2.hook_scale', 'blocks.23.ln2.hook_normalized', 'blocks.23.mlp.hook_pre', 'blocks.23.mlp.hook_pre_linear', 'blocks.23.mlp.hook_post', 'blocks.23.hook_mlp_out', 'blocks.23.hook_resid_post', 'blocks.24.hook_resid_pre', 'blocks.24.ln1.hook_scale', 'blocks.24.ln1.hook_normalized', 'blocks.24.attn.hook_q', 'blocks.24.attn.hook_k', 'blocks.24.attn.hook_v', 'blocks.24.attn.hook_rot_q', 'blocks.24.attn.hook_rot_k', 'blocks.24.attn.hook_attn_scores', 'blocks.24.attn.hook_pattern', 'blocks.24.attn.hook_z', 'blocks.24.hook_attn_out', 'blocks.24.hook_resid_mid', 'blocks.24.ln2.hook_scale', 'blocks.24.ln2.hook_normalized', 'blocks.24.mlp.hook_pre', 'blocks.24.mlp.hook_pre_linear', 'blocks.24.mlp.hook_post', 'blocks.24.hook_mlp_out', 'blocks.24.hook_resid_post', 'blocks.25.hook_resid_pre', 'blocks.25.ln1.hook_scale', 'blocks.25.ln1.hook_normalized', 'blocks.25.attn.hook_q', 'blocks.25.attn.hook_k', 'blocks.25.attn.hook_v', 'blocks.25.attn.hook_rot_q', 'blocks.25.attn.hook_rot_k', 'blocks.25.attn.hook_attn_scores', 'blocks.25.attn.hook_pattern', 'blocks.25.attn.hook_z', 'blocks.25.hook_attn_out', 'blocks.25.hook_resid_mid', 'blocks.25.ln2.hook_scale', 'blocks.25.ln2.hook_normalized', 'blocks.25.mlp.hook_pre', 'blocks.25.mlp.hook_pre_linear', 'blocks.25.mlp.hook_post', 'blocks.25.hook_mlp_out', 'blocks.25.hook_resid_post', 'blocks.26.hook_resid_pre', 'blocks.26.ln1.hook_scale', 'blocks.26.ln1.hook_normalized', 'blocks.26.attn.hook_q', 'blocks.26.attn.hook_k', 'blocks.26.attn.hook_v', 'blocks.26.attn.hook_rot_q', 'blocks.26.attn.hook_rot_k', 'blocks.26.attn.hook_attn_scores', 'blocks.26.attn.hook_pattern', 'blocks.26.attn.hook_z', 'blocks.26.hook_attn_out', 'blocks.26.hook_resid_mid', 'blocks.26.ln2.hook_scale', 'blocks.26.ln2.hook_normalized', 'blocks.26.mlp.hook_pre', 'blocks.26.mlp.hook_pre_linear', 'blocks.26.mlp.hook_post', 'blocks.26.hook_mlp_out', 'blocks.26.hook_resid_post', 'blocks.27.hook_resid_pre', 'blocks.27.ln1.hook_scale', 'blocks.27.ln1.hook_normalized', 'blocks.27.attn.hook_q', 'blocks.27.attn.hook_k', 'blocks.27.attn.hook_v', 'blocks.27.attn.hook_rot_q', 'blocks.27.attn.hook_rot_k', 'blocks.27.attn.hook_attn_scores', 'blocks.27.attn.hook_pattern', 'blocks.27.attn.hook_z', 'blocks.27.hook_attn_out', 'blocks.27.hook_resid_mid', 'blocks.27.ln2.hook_scale', 'blocks.27.ln2.hook_normalized', 'blocks.27.mlp.hook_pre', 'blocks.27.mlp.hook_pre_linear', 'blocks.27.mlp.hook_post', 'blocks.27.hook_mlp_out', 'blocks.27.hook_resid_post', 'blocks.28.hook_resid_pre', 'blocks.28.ln1.hook_scale', 'blocks.28.ln1.hook_normalized', 'blocks.28.attn.hook_q', 'blocks.28.attn.hook_k', 'blocks.28.attn.hook_v', 'blocks.28.attn.hook_rot_q', 'blocks.28.attn.hook_rot_k', 'blocks.28.attn.hook_attn_scores', 'blocks.28.attn.hook_pattern', 'blocks.28.attn.hook_z', 'blocks.28.hook_attn_out', 'blocks.28.hook_resid_mid', 'blocks.28.ln2.hook_scale', 'blocks.28.ln2.hook_normalized', 'blocks.28.mlp.hook_pre', 'blocks.28.mlp.hook_pre_linear', 'blocks.28.mlp.hook_post', 'blocks.28.hook_mlp_out', 'blocks.28.hook_resid_post', 'blocks.29.hook_resid_pre', 'blocks.29.ln1.hook_scale', 'blocks.29.ln1.hook_normalized', 'blocks.29.attn.hook_q', 'blocks.29.attn.hook_k', 'blocks.29.attn.hook_v', 'blocks.29.attn.hook_rot_q', 'blocks.29.attn.hook_rot_k', 'blocks.29.attn.hook_attn_scores', 'blocks.29.attn.hook_pattern', 'blocks.29.attn.hook_z', 'blocks.29.hook_attn_out', 'blocks.29.hook_resid_mid', 'blocks.29.ln2.hook_scale', 'blocks.29.ln2.hook_normalized', 'blocks.29.mlp.hook_pre', 'blocks.29.mlp.hook_pre_linear', 'blocks.29.mlp.hook_post', 'blocks.29.hook_mlp_out', 'blocks.29.hook_resid_post', 'blocks.30.hook_resid_pre', 'blocks.30.ln1.hook_scale', 'blocks.30.ln1.hook_normalized', 'blocks.30.attn.hook_q', 'blocks.30.attn.hook_k', 'blocks.30.attn.hook_v', 'blocks.30.attn.hook_rot_q', 'blocks.30.attn.hook_rot_k', 'blocks.30.attn.hook_attn_scores', 'blocks.30.attn.hook_pattern', 'blocks.30.attn.hook_z', 'blocks.30.hook_attn_out', 'blocks.30.hook_resid_mid', 'blocks.30.ln2.hook_scale', 'blocks.30.ln2.hook_normalized', 'blocks.30.mlp.hook_pre', 'blocks.30.mlp.hook_pre_linear', 'blocks.30.mlp.hook_post', 'blocks.30.hook_mlp_out', 'blocks.30.hook_resid_post', 'blocks.31.hook_resid_pre', 'blocks.31.ln1.hook_scale', 'blocks.31.ln1.hook_normalized', 'blocks.31.attn.hook_q', 'blocks.31.attn.hook_k', 'blocks.31.attn.hook_v', 'blocks.31.attn.hook_rot_q', 'blocks.31.attn.hook_rot_k', 'blocks.31.attn.hook_attn_scores', 'blocks.31.attn.hook_pattern', 'blocks.31.attn.hook_z', 'blocks.31.hook_attn_out', 'blocks.31.hook_resid_mid', 'blocks.31.ln2.hook_scale', 'blocks.31.ln2.hook_normalized', 'blocks.31.mlp.hook_pre', 'blocks.31.mlp.hook_pre_linear', 'blocks.31.mlp.hook_post', 'blocks.31.hook_mlp_out', 'blocks.31.hook_resid_post', 'ln_final.hook_scale', 'ln_final.hook_normalized'])\n"
     ]
    }
   ],
   "source": [
    "print(activation_cache.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5833, -11.0975,   4.4770,  -3.4971,  -3.1493], device='cuda:0')\n",
      "torch.Size([1, 6, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.0341, 1.0428, 1.1330, 0.9819, 0.8857], device='cuda:0',\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(logits[0, -1, :5])\n",
    "last_token_accum = accum_resid[-1, 0, -1]\n",
    "print(activation_cache['ln_final.hook_scale'].shape)\n",
    "last_token_accum = last_token_accum * torch.rsqrt(last_token_accum.pow(2).mean(-1, keepdim=True) + 1e-6)\n",
    "last_token_accum = last_token_accum * torch.sqrt(activation_cache['ln_final.hook_scale'][0, -1, 0])\n",
    "unembedded = last_token_accum @ W_unembedding\n",
    "(unembedded / logits[0, -1])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "icl_ds = pd.read_csv(f'ICL-GD/ICL-AGNews-Size100-8Dem.csv').drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model succeeds on item 63 - if you don't believe me run the code below\n",
    "\n",
    "i = 63\n",
    "\n",
    "# rng = np.random.default_rng(seed=0)\n",
    "# while True:\n",
    "#     i = rng.integers(len(icl_ds))\n",
    "#     print(i)\n",
    "#     prompt = icl_ds['ICL Prompt'][i]\n",
    "#     answer = icl_ds['Answer'][i]\n",
    "#     icl_prompt_tokens = model.to_tokens(prompt).detach().cpu()\n",
    "#     icl_out = model.generate(icl_prompt_tokens, max_new_tokens=1, temperature=0, verbose=False).squeeze()\n",
    "#     if model.to_string(icl_out[-1]) == answer:\n",
    "#         print('Found!')\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify the news articles into the categories of World, Sports, Business, and Technology.\n",
      "News: EMC Makes SMB, Channel, Macintosh Play With Dantz Acquisition EMC scored a triple-play with the acquisition of Dantz Development, a small developer of data backup and restore software under the Retrospect brand.\n",
      "Category: Technology\n",
      "News: Legal peer-to-peer services: Gimmick or Genius? Few in the tech world need an introduction to Napster #39;s founder, the college dropout whose revolutionary file-swapping technology shook the foundations of the \\$11bn record industry.\n",
      "Category: Technology\n",
      "News: ONGC #39;s 10th acquisition abroad Public sector behemoth Oil and Natural Gas Corporation Ltd on Monday said it has acquired an offshore oil field in Western Australia.\n",
      "Category: Business\n",
      "News: Novell, Microsoft settle row Novell Inc. of Waltham is getting a half-billion-dollar check from Microsoft Corp. to settle an antitrust case that #39;s never been filed.\n",
      "Category: Business\n",
      "News: Weakened Arafat Heads for France, Cancer Suspected  RAMALLAH, West Bank (Reuters) - Palestinian leader Yasser  Arafat, weakened by what doctors think may be leukemia, flew  for treatment in France on Friday from the besieged West Bank  headquarters where he had been pinned for over 2-1/2 years.\n",
      "Category: World\n",
      "News: China #39;s economy up 9.5 in 1st 9 months China #39;s economy grew by 9.5 percent year-on-year in the first nine months of this year, Spokesman Zheng Jingping for the National Bureau of Statistics announced in Beijing Friday.\n",
      "Category: Business\n",
      "News: Hostage Takers Widen Demands Beyond Iraqi Affairs BAGHDAD, Aug 29 (AFP) - For the first time since the kidnappings of foreigners started in Iraq in April, hostage takers have set conditions external to the country by demanding that France lift a ban on Islamic headscarves in state schools.\n",
      "Category: World\n",
      "News: Ecclestone Trust Engineered Control #39; of F-1 Racing, Court Told A Bernie Ecclestone family trust has engineered control #39; #39; over Formula One motor racing by unlawfully appointing directors to the sport #39;s operating companies, a lawyer for three banks told a London court.\n",
      "Category: Sports\n",
      "News: Does new Peoplesoft CEO signal a buyout? The ouster of Craig Conway and the return of Dave Duffield could be a prelude to PeopleSoft accepting Oracle's offer.\n",
      "Category:\n",
      "Business\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = icl_ds.loc[i, 'ICL Prompt']\n",
    "print(prompt)\n",
    "probs = layer_prob(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'probs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(probs\u001b[38;5;241m.\u001b[39mcpu())\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConfidence Level per Layer\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'probs' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(probs.cpu())\n",
    "plt.set_title('Confidence Level per Layer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama7BHelper\n",
    "Llama 2 7b Wrapper Taken from https://github.com/nrimsky/LM-exp/tree/main/intermediate_decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from torch.nn.modules.container import ModuleList\n",
    "\n",
    "\n",
    "# class PermutationLayer(torch.nn.Module):\n",
    "#     def __init__(self, perm):\n",
    "#         '''\n",
    "#         :params perm: int tensor of size (seq_length, ) that speficies the permutation to apply to the layer\n",
    "#         '''\n",
    "#         self.perm = perm.to(device)\n",
    "#         super().__init__()\n",
    "    \n",
    "#     def forward(self, *args, **kwargs):\n",
    "#         input = args[0]         # Input of size (batch, seq_length, d_model)\n",
    "#         return input[:, self.perm, :]\n",
    "\n",
    "@dataclass\n",
    "class PermutationIntervention:\n",
    "    perm: torch.tensor          # int tensor of size (seq_length, ) that speficies the permutation to apply to the layer\n",
    "    before_layer_num: int       # The layer number of the transformer (1st is 0) before which to perform permutation\n",
    "\n",
    "\n",
    "class AttnWrapper(torch.nn.Module):\n",
    "    def __init__(self, attn, save_all=False):\n",
    "        super().__init__()\n",
    "        self.attn = attn\n",
    "        self.activations = None\n",
    "        self.add_tensor = None\n",
    "        self.save_all = save_all\n",
    "\n",
    "    def forward(self, *args, **kwargs):\n",
    "        output = self.attn(*args, **kwargs)\n",
    "        if self.add_tensor is not None:\n",
    "            output = (output[0] + self.add_tensor,)+output[1:]\n",
    "        if self.save_all:\n",
    "            self.activations = output[0]\n",
    "        return output\n",
    "\n",
    "    def reset(self):\n",
    "        self.activations = None\n",
    "        self.add_tensor = None\n",
    "\n",
    "class BlockOutputWrapper(torch.nn.Module):\n",
    "    def __init__(self, block, unembed_matrix, norm, save_all=False):\n",
    "        super().__init__()\n",
    "        self.block = block\n",
    "        self.unembed_matrix = unembed_matrix\n",
    "        self.norm = norm\n",
    "\n",
    "        self.block.self_attn = AttnWrapper(self.block.self_attn, save_all=save_all)\n",
    "        self.post_attention_layernorm = self.block.post_attention_layernorm\n",
    "\n",
    "        self.attn_mech_output_unembedded = None\n",
    "        self.intermediate_res_unembedded = None\n",
    "        self.mlp_output_unembedded = None\n",
    "        self.block_output_unembedded = None\n",
    "\n",
    "        self.permutation = None\n",
    "        self.save_all = save_all\n",
    "\n",
    "\n",
    "    def forward(self, *args, **kwargs):\n",
    "        input = args[0]   # (batch, seq_length, d_model)\n",
    "        if self.permutation is not None:\n",
    "            # prev_input = input\n",
    "            input = input[:, self.permutation, :]\n",
    "            # assert not torch.all(torch.isclose(prev_input, input))\n",
    "        output = self.block(input, *args[1:], **kwargs)\n",
    "        self.block_output_unembedded = self.unembed_matrix(self.norm(output[0]))\n",
    "        if self.save_all:\n",
    "            attn_output = self.block.self_attn.activations\n",
    "            self.attn_mech_output_unembedded = self.unembed_matrix(self.norm(attn_output))\n",
    "            attn_output += input\n",
    "            self.intermediate_res_unembedded = self.unembed_matrix(self.norm(attn_output))\n",
    "            mlp_output = self.block.mlp(self.post_attention_layernorm(attn_output))\n",
    "            self.mlp_output_unembedded = self.unembed_matrix(self.norm(mlp_output))\n",
    "        return output\n",
    "\n",
    "    def attn_add_tensor(self, tensor):\n",
    "        self.block.self_attn.add_tensor = tensor\n",
    "    \n",
    "    def add_permutation(self, perm):\n",
    "        self.permutation = perm\n",
    "    \n",
    "    def clean_permutation(self):\n",
    "        self.permutation = None\n",
    "\n",
    "    def reset(self):\n",
    "        self.block.self_attn.reset()\n",
    "        self.permutation = None\n",
    "\n",
    "    def get_attn_activations(self):\n",
    "        return self.block.self_attn.activations\n",
    "\n",
    "class Llama7BHelper:\n",
    "    def __init__(self, model, token=None):\n",
    "        '''\n",
    "        model: \"meta-llama/Llama-2-7b-hf\" model\n",
    "        '''\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\", use_auth_token=token)\n",
    "        self.model = model\n",
    "        self.orig_model_layers = self.model.model.layers\n",
    "        self.model.model.layers = ModuleList(\n",
    "            [BlockOutputWrapper(layer, self.model.lm_head, self.model.model.norm) for layer in self.model.model.layers]\n",
    "        )\n",
    "\n",
    "    def generate_text(self, prompt, max_length=100):\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\")\n",
    "        generate_ids = self.model.generate(inputs.input_ids.to(self.device), max_length=max_length)\n",
    "        return self.tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "\n",
    "\n",
    "    def forward(self, prompt, interventions=[]):\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\")\n",
    "        input_ids = inputs['input_ids'][0]\n",
    "        for intrv in interventions:\n",
    "            if isinstance(intrv, PermutationIntervention):\n",
    "                assert intrv.perm.shape[0] == len(input_ids), f'Permutation index list of size {alt.perm.shape[0]} but input sequence of length {len(input_ids)}'\n",
    "                self.layers[intrv.before_layer_num].add_permutation(intrv.perm)\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(inputs.input_ids.to(self.device)).logits\n",
    "            # Cleanup\n",
    "            for intrv in interventions:\n",
    "                if isinstance(intrv, PermutationIntervention):\n",
    "                    self.layers[intrv.before_layer_num].clean_permutation()\n",
    "            return logits\n",
    "\n",
    "    def set_add_attn_output(self, layer, add_output):\n",
    "        self.model.model.layers[layer].attn_add_tensor(add_output)\n",
    "\n",
    "    def get_attn_activations(self, layer):\n",
    "        return self.model.model.layers[layer].get_attn_activations()\n",
    "\n",
    "    def reset_all(self):\n",
    "        for layer in self.model.model.layers:\n",
    "            layer.reset()\n",
    "\n",
    "    def print_decoded_activations(self, decoded_activations, label, topk=10):\n",
    "        softmaxed = torch.nn.functional.softmax(decoded_activations[0][-1], dim=-1)\n",
    "        values, indices = torch.topk(softmaxed, topk)\n",
    "        probs_percent = [int(v * 100) for v in values.tolist()]\n",
    "        tokens = self.tokenizer.batch_decode(indices.unsqueeze(-1))\n",
    "        print(label, list(zip(tokens, probs_percent)))\n",
    "    \n",
    "    @property\n",
    "    def layers(self):\n",
    "        return self.model.model.layers\n",
    "    \n",
    "    @layers.setter\n",
    "    def layers(self, layers):\n",
    "        self.model.model.layers = layers\n",
    "\n",
    "\n",
    "    def decode_all_layers(self, text, topk=10, print_attn_mech=True, print_intermediate_res=True, print_mlp=True, print_block=True):\n",
    "        self.get_logits(text)\n",
    "        for i, layer in enumerate(self.model.model.layers):\n",
    "            print(f'Layer {i}: Decoded intermediate outputs')\n",
    "            if print_attn_mech:\n",
    "                self.print_decoded_activations(layer.attn_mech_output_unembedded, 'Attention mechanism', topk=topk)\n",
    "            if print_intermediate_res:\n",
    "                self.print_decoded_activations(layer.intermediate_res_unembedded, 'Intermediate residual stream', topk=topk)\n",
    "            if print_mlp:\n",
    "                self.print_decoded_activations(layer.mlp_output_unembedded, 'MLP output', topk=topk)\n",
    "            if print_block:\n",
    "                self.print_decoded_activations(layer.block_output_unembedded, 'Block output', topk=topk)\n",
    "    \n",
    "    def reset_hf_model(self):\n",
    "        self.model.model.layers = self.orig_model_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53d549ec4e6e48faa0b2a6857dec846d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hf_model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-hf\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.reset_hf_model()  # Uncomment if you want to rebuild llama7bhelper without reloading hf model\n",
    "model = Llama7BHelper(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orig_layers = model.layers\n",
    "# model.model.model.layers = model.layers + model.layers\n",
    "# model.model.model.layers = orig_layers\n",
    "# assert(len(model.layers) == 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_lens(model : Llama7BHelper):\n",
    "    '''\n",
    "    Returns tensor of size (layer, pos, d_vocab) with probability distribution predictions for each token,\n",
    "            in each layer. ASSUMES model.forward() has been run prior to function, and reset_all() has not been called\n",
    "    '''\n",
    "    layer_probs = []\n",
    "    for layer in model.layers:\n",
    "        inter_logits = layer.block_output_unembedded.squeeze(dim=0)   # pos, d_vocab\n",
    "        inter_probs = torch.softmax(inter_logits, dim=-1)\n",
    "        layer_probs.append(inter_probs)\n",
    "    return torch.stack(layer_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_icl_zsl_confidence(model, icl_prompt, zsl_prompt, correct_answer_str, icl_probs, zsl_probs):\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(10, 10))\n",
    "    fig.suptitle('Confidence in Final Answer Per Layer')\n",
    "    for i, prompt in enumerate((icl_prompt, zsl_prompt)):\n",
    "        print(prompt)\n",
    "        prompt_type = 'ICL' if prompt == icl_prompt else 'ZSL'\n",
    "        prob_lens = icl_probs if prompt == icl_prompt else zsl_probs\n",
    "        final_answer_token = torch.argmax(prob_lens[-1, -1])\n",
    "        final_answer_str = model.tokenizer.batch_decode(final_answer_token.unsqueeze(0))[0]\n",
    "        print(f'Model Answer: {final_answer_str}, Correct Answer: {correct_answer_str}')\n",
    "        correct = final_answer_str == correct_answer_str\n",
    "        correct_str = \"Correct\" if correct else \"Wrong\"\n",
    "        correct_answer_token = model.tokenizer.encode(text=correct_answer_str, add_special_tokens=False)[0]\n",
    "        if correct:\n",
    "            assert correct_answer_token == final_answer_token, (correct_answer_token, final_answer_token)\n",
    "        \n",
    "\n",
    "        final_answer_confidence = prob_lens[:, -1, final_answer_token].cpu()\n",
    "        correct_answer_confidence = prob_lens[:, -1, correct_answer_token].cpu()\n",
    "        \n",
    "        for j in (0, 1):\n",
    "            ax[i][j].plot(final_answer_confidence, label=f'Final ({correct_str}) Answer')\n",
    "            if not correct:\n",
    "                ax[i][j].plot(correct_answer_confidence, label='Correct Answer')\n",
    "            ax[i][j].set_title(f'{\"Log \" if j == 1 else ''}Confidence - {prompt_type}')\n",
    "            if j == 1:\n",
    "                ax[i][j].semilogy()\n",
    "            ax[i][j].legend()\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dem_begin_indices(model, icl_prompt):\n",
    "    '''\n",
    "    Returns list of indices in token list in which each demonstration of the icl prompt starts (including test prompt)\n",
    "    '''\n",
    "    ret = []\n",
    "    start_idxs = [m.start() for m in re.finditer('\\nNews', icl_prompt)]\n",
    "    for idx in start_idxs:\n",
    "        tokens = model.tokenizer.encode(icl_prompt[:idx])\n",
    "        ret.append(len(tokens))\n",
    "    return ret\n",
    "\n",
    "def get_random_dem_permutation(model, icl_prompt, seed=None):\n",
    "    '''\n",
    "    Returns permutation indexes than can be applied to the encoding of icl_prompt in order to shuffle the demonstrations\n",
    "    '''\n",
    "    ret = []\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "    dem_begin_indices = get_dem_begin_indices(model, icl_prompt)\n",
    "    dem_order = np.arange(0, len(dem_begin_indices) - 1)  # Not including test prompt\n",
    "    rng.shuffle(dem_order)\n",
    "    ret += list(np.arange(0, dem_begin_indices[0]))\n",
    "    for old_pos in dem_order:\n",
    "        ret += list(\n",
    "            np.arange(dem_begin_indices[old_pos], dem_begin_indices[old_pos + 1])\n",
    "        )\n",
    "    orig_tokens = model.tokenizer.encode(icl_prompt)\n",
    "    ret += list(np.arange(dem_begin_indices[-1], len(orig_tokens)))\n",
    "    assert len(ret) == len(orig_tokens)\n",
    "    return torch.tensor(ret)\n",
    "\n",
    "def get_semi_preserving_permutation(model, icl_prompt, seed=None):\n",
    "    '''\n",
    "    Returns permutation that jumbles up everything after the initial instruction and before the final test prompt.\n",
    "    '''\n",
    "    ret = []\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "    dem_begin_indices = get_dem_begin_indices(model, icl_prompt)\n",
    "    all_middle_indices = np.arange(start=dem_begin_indices[0], stop=dem_begin_indices[-1])\n",
    "    rng.shuffle(all_middle_indices)\n",
    "    ret += list(np.arange(0, dem_begin_indices[0]))\n",
    "    ret += list(all_middle_indices)\n",
    "    orig_tokens = model.tokenizer.encode(icl_prompt)\n",
    "    ret += list(np.arange(dem_begin_indices[-1], len(orig_tokens)))\n",
    "    assert len(ret) == len(orig_tokens)\n",
    "    return torch.tensor(ret)\n",
    "\n",
    "def get_non_preserving_permutation(model, icl_prompt, seed=None):\n",
    "    '''\n",
    "    Returns permutation that jumbles up literally everything\n",
    "    '''\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "    orig_tokens = model.tokenizer.encode(icl_prompt)\n",
    "    indices = np.arange(0, len(orig_tokens))\n",
    "    rng.shuffle(indices)\n",
    "    return torch.tensor(indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "icl_ds = pd.read_csv(f'ICL-GD/ICL-AGNews-Size100-8Dem.csv').drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Permutation:\n",
      "<s> Classify the news articles into the categories of World, Sports, Business, and Technology.\n",
      "News: Report: NHL agent loses certification According to a report in the Ottawa Sun, an NHL agent has lost his certification for leaking information about a players #39; association website to a reporter from a Minnesota newspaper.\n",
      "Category: Sports\n",
      "News: Bodies of 49 Iraqi soldiers found The bodies of 49 Iraqi soldiers have been found shot dead Northeast of Baghdad, police and Iraqi National Guard officers said. They said 37 bodies had been recovered on Saturday and another 12 earlier on a \n",
      "Category: World\n",
      "News: LeBron James scores 26 points as Cleveland beats the Bulls 97-74 LeBron James enjoys the Cleveland Cavaliers #39; teamwork even more than his individual accomplishments. One led to the other Saturday night as James scored 26 points to become the youngest player \n",
      "Category: Sports\n",
      "News: Israel Boosts Security for Sharon, Others Israeli soldiers carry the coffin, wrapped by an Israeli flag, of 22-year-old Army Staff Sgt. Yair Turgeman during his funeral in Jerusalem, Wednesday Oct 20, 2004.\n",
      "Category: World\n",
      "News: Microsoft Cracks Down on Xbox Changes (AP) AP - In the days before Microsoft Corp. released the hotly anticipated Halo 2 video game for the Xbox game console, some gamers noticed a sudden spike in the number of people being kicked off the company's online game service. That was no coincidence.\n",
      "Category: Technology\n",
      "News: Fifteen African presidents pledge peace in Great Lakes (AFP) AFP - Fifteen African presidents and UN chief Kofi Annan signed a common declaration pledging to promote peace and security in the continent's volatile Great Lakes region.\n",
      "Category: World\n",
      "News: Big gains for Krishnamurthi (SiliconValley.com) SiliconValley.com - Engineering star Ashok Krishnamurthi quit his job at Juniper Networks with more than  #36;2 million in gains from exercising options and selling shares in his final weeks with the Sunnyvale networking company.\n",
      "Category: Technology\n",
      "News: DHL scraps Brussels growth plan Courier firm DHL is ditching plans to site its international hub in Brussels at a likely cost of 1,700 jobs by 2008. Negotiations with local and federal authorities over increasing the number of night flights have failed, the firm told BBC News Online.\n",
      "Category: Business\n",
      "News: Racketeering case against tobacco industry to begin WASHINGTON -- It has taken five years of pretrial skirmishing, but testimony will finally begin tomorrow in the government's massive racketeering case alleging that the tobacco industry defrauded and misled the American public for almost 50 years about the health risks of cigarette smoking.\n",
      "Category:\n",
      "After Permutation:\n",
      "<s> Classify the news articles into the categories of World, Sports, Business, and Technology.\n",
      "News: LeBron James scores 26 points as Cleveland beats the Bulls 97-74 LeBron James enjoys the Cleveland Cavaliers #39; teamwork even more than his individual accomplishments. One led to the other Saturday night as James scored 26 points to become the youngest player \n",
      "Category: Sports\n",
      "News: Microsoft Cracks Down on Xbox Changes (AP) AP - In the days before Microsoft Corp. released the hotly anticipated Halo 2 video game for the Xbox game console, some gamers noticed a sudden spike in the number of people being kicked off the company's online game service. That was no coincidence.\n",
      "Category: Technology\n",
      "News: Israel Boosts Security for Sharon, Others Israeli soldiers carry the coffin, wrapped by an Israeli flag, of 22-year-old Army Staff Sgt. Yair Turgeman during his funeral in Jerusalem, Wednesday Oct 20, 2004.\n",
      "Category: World\n",
      "News: Big gains for Krishnamurthi (SiliconValley.com) SiliconValley.com - Engineering star Ashok Krishnamurthi quit his job at Juniper Networks with more than  #36;2 million in gains from exercising options and selling shares in his final weeks with the Sunnyvale networking company.\n",
      "Category: Technology\n",
      "News: Fifteen African presidents pledge peace in Great Lakes (AFP) AFP - Fifteen African presidents and UN chief Kofi Annan signed a common declaration pledging to promote peace and security in the continent's volatile Great Lakes region.\n",
      "Category: World\n",
      "News: Report: NHL agent loses certification According to a report in the Ottawa Sun, an NHL agent has lost his certification for leaking information about a players #39; association website to a reporter from a Minnesota newspaper.\n",
      "Category: Sports\n",
      "News: Bodies of 49 Iraqi soldiers found The bodies of 49 Iraqi soldiers have been found shot dead Northeast of Baghdad, police and Iraqi National Guard officers said. They said 37 bodies had been recovered on Saturday and another 12 earlier on a \n",
      "Category: World\n",
      "News: DHL scraps Brussels growth plan Courier firm DHL is ditching plans to site its international hub in Brussels at a likely cost of 1,700 jobs by 2008. Negotiations with local and federal authorities over increasing the number of night flights have failed, the firm told BBC News Online.\n",
      "Category: Business\n",
      "News: Racketeering case against tobacco industry to begin WASHINGTON -- It has taken five years of pretrial skirmishing, but testimony will finally begin tomorrow in the government's massive racketeering case alleging that the tobacco industry defrauded and misled the American public for almost 50 years about the health risks of cigarette smoking.\n",
      "Category:\n",
      "After Semi Preserving Permutation:\n",
      "<s> Classify the news articles into the categories of World, Sports, Business, and Technology.. carryanurakesi in\n",
      " found sp growthrier a a has World Microsoft;itch - game\n",
      " fromAP According Ott: pres job Fifqi3News and at X soldiersper before console Onlineortheast anticip on saidad Le Br authorities D evenatile found pres: Technologyations Fif Business Ash African by N: theley fl increasing70 and rep;box: Worldaron enjoeli Wedurg69 keli That.ging -nam on police a lost, his noticed sP people bodies.27ish # plan international\n",
      "s1  K for' World firm p the hisqi of site:Category. the,Category.8ellings havenamof reportin g  Microsoft: thes number James92com.4emanains Sh3: of. Sportsuss cost security.\n",
      "aking in20 thenyNewsidents on the: the gels: N more News p starotithersing Juni Chhd game The as  withCategoryHL become deadawa Cleveland Cou andday had during quit7orterth gamicon wrapped # said Jerusalemnes L3cisidents released Sports team ( inP Security4-uss.B\n",
      " D ights Lains is Ira likelygt in Technology and earlier  an to offair with shares0 Br Kr for le chief #old at Great scra Israeli DownCategory told online, Oct website, have options\n",
      "ers Army asCategory, S days Bo2 cert: number information hot) been with d coinc Bull3 service weeks federal Israalo ofthingAF his1 declarationB the\n",
      "9s:: thanteen ( a its ,Val association, signed networking Kr of4els than Neg Cav sudden Great\n",
      "ost video agent the los the theValickedteenCategory continentNews- in9) forlyHL\n",
      " AP plansies Corledge other in. failed\n",
      " jobs to officers peace fun region Isra ali. Y a0 James common being million Big Network by0 players his Lees BBC a' African: for) from of2Category Ann2 Bodcomronur of: Staff flagqi One  scored shot AF Minnesota be points and Saturday about UN ( James accomplish a N T moreats his\n",
      ".eralyear exer been individual the CraHL no the\n",
      " They firm Guard Nationalv In4 Bag2 coff final soldiers volish hub scores\n",
      " in led bodiesSilicon to est company Saturday0 ificationNews ron\n",
      "ments,  in2 peaceCategory theNews anotherificationHL2 work night newspaper0idence points X company9 Sunp of Silcks promotes\n",
      " local\n",
      "ys toakes night O an:6ley- recoveredike the: to was Report overale News Ira Ira6 Cleveland;led playerbox, Engineering,.okNewsated aanges game.ers H 2 - young:7 to agent SunNews and soldiers some certi ps\n",
      "News: Racketeering case against tobacco industry to begin WASHINGTON -- It has taken five years of pretrial skirmishing, but testimony will finally begin tomorrow in the government's massive racketeering case alleging that the tobacco industry defrauded and misled the American public for almost 50 years about the health risks of cigarette smoking.\n",
      "Category:\n",
      "After Non Preserving Permutation:\n",
      "of9 hasingofirmete UN Big of, common case N nightCategoryify, in\n",
      " to The0 players Network Microsoft jobuss moreareticon agent7 almost- massive-raNews. failed articles mis for World- James cost has ( Ash growth. a said Engineering said8 withur to have  the0 Minnesota found than:9air 3  a: HCategory beforeering American an ( shot g s pre News sudden the9essack AP JuniB0\n",
      " ofP --0ck Sports quitNewsleyacco have: signed2News Bullurgly company:Category player They.) scra1s becomeains, andp:idence6s toost onNews,ies' andVal gameHL in people.ishing caseys sk firm4ed game Israel about industry the Sh continent7 is,iud in a Ira X flag:7AF Down the3 international4 - regionations ris Rification lostday aightsSil been6: onqiacco recovered  siteiold as News Br. Saturday: ofali los bodies told aony, finally industry. been of Security declarationicked\n",
      " presicon in numberidents) Bod alleg. the Sun Jerusalem against Bo to Ann,2 sp Technology2eman.akingper at4 to the and2 b Ottron officers African Sports1ckseliNews Cou cis the plansCategoryqi; five4 his gam over,s\n",
      " bodies a agent was T smelling a Great from as Cleveland IsraawaCategoryled the more N foundidents newspaper that ra individual Neganth Bag prescom his2 to firm video Cra by final a Great promoteete numberVal points2 L on<s> Fif, the6 federal Army online Chps an of years team likely According to:ats increasing carryerstriv security service begin scored. W than. Xatile Kr Cor\n",
      " Staff theHLyear5. public) the theish9 thes:in chief  even World in k' Sil some game report D Business inhdoking begin;: volale console' BBCNews to.sAP but  AF days his no theB to National peace for scores WorldthersNewsok9gingP noticednes Le g Fif\n",
      "7ksleythteen It led options coinc Y\n",
      " N young Br #ron\n",
      ":eral\n",
      " will beated inuring information2 -HL accomplish categories cig about2 government:box health Ira in Wed at soldiers night rep and. deadbox K Sun  into for off\n",
      "ING association Microsoft jobs ThatersCategory Krrier of Business:orrow soldiers HL  ny by p other and the hub. plan James star ofal Technology news the Technology cert O being Lakes;\n",
      " for website coff from theering \n",
      ", #elsledge0 Jamesels d Isra the his\n",
      " networking, of2eli Oct fun weeks Ira0: during soldiers3Category taken another peace and.\n",
      "Tte policeqiification Class Saturday its enjo years Sgt had,03 le earlier, exer, Daron:  Africanusscom #ingled pointsteen of. forest Report\n",
      "2: Leadalo Sports company\n",
      " Online hisike the defains\n",
      " andorter\n",
      "ish Clevelandnam - One itch localnam: Worldi authorities sharesangesNews anticip tom0 InASH wrapped  withON hototi (Category GuardCategoryments andortheast Cav the million the fl in p: testim released certakeswork withb\n"
     ]
    }
   ],
   "source": [
    "print('Before Permutation:')\n",
    "row = icl_ds.iloc[20]\n",
    "print(model.tokenizer.decode(model.tokenizer.encode(row['ICL Prompt'])))\n",
    "perm = get_random_dem_permutation(model, row['ICL Prompt'], seed=0)\n",
    "after_perm = model.tokenizer.decode(\n",
    "    np.array(model.tokenizer.encode(row['ICL Prompt']))[perm]\n",
    ")\n",
    "print('After Permutation:')\n",
    "print(after_perm)\n",
    "print('After Semi Preserving Permutation:')\n",
    "perm = get_semi_preserving_permutation(model, row['ICL Prompt'], seed=0)\n",
    "after_perm = model.tokenizer.decode(\n",
    "    np.array(model.tokenizer.encode(row['ICL Prompt']))[perm]\n",
    ")\n",
    "print(after_perm)\n",
    "print('After Non Preserving Permutation:')\n",
    "perm = get_non_preserving_permutation(model, row['ICL Prompt'], seed=0)\n",
    "after_perm = model.tokenizer.decode(\n",
    "    np.array(model.tokenizer.encode(row['ICL Prompt']))[perm]\n",
    ")\n",
    "print(after_perm)"
   ]
  }
]
}
